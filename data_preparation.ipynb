{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1280f518",
   "metadata": {},
   "source": [
    "# Netflix Dataset Preparation - Milestone 1\n",
    "## Week 1 & 2: Requirements & Dataset Preparation\n",
    "\n",
    "**Project Goals:**\n",
    "- Define project scope and success metrics\n",
    "- Load the Netflix Kaggle dataset\n",
    "- Clean the dataset (handle missing values, remove duplicates)\n",
    "- Normalize categorical features such as genre, rating, and country\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d3c56f",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "First, we'll import the necessary libraries for data manipulation and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace11f40",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel '.venv (Python 3.13.3)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"✓ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76d8a15",
   "metadata": {},
   "source": [
    "## 2. Load the Netflix Dataset\n",
    "Load the Netflix titles dataset from the CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18a4719",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel '.venv (Python 3.13.3)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def load_dataset(filepath='C:\\Users\\Kavya Jain\\OneDrive\\Desktop\\Project1\\netflix\\Data\\netflix_titles.csv'):\n",
    "    \"\"\"Load the Netflix dataset from CSV file.\"\"\"\n",
    "    print(\"=\" * 70)\n",
    "    print(\"LOADING DATASET\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(filepath)\n",
    "        print(f\"✓ Dataset loaded successfully!\")\n",
    "        print(f\"  - Shape: {df.shape[0]} rows × {df.shape[1]} columns\")\n",
    "        print(f\"  - Columns: {list(df.columns)}\")\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        print(f\"✗ Error: File '{filepath}' not found!\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error loading dataset: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Load the dataset\n",
    "df = load_dataset('netflix_titles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b9f0f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 8807 entries, 0 to 8806\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Non-Null Count  Dtype\n",
      "---  ------        --------------  -----\n",
      " 0   show_id       8807 non-null   str  \n",
      " 1   type          8807 non-null   str  \n",
      " 2   title         8807 non-null   str  \n",
      " 3   director      6173 non-null   str  \n",
      " 4   cast          7982 non-null   str  \n",
      " 5   country       7976 non-null   str  \n",
      " 6   date_added    8797 non-null   str  \n",
      " 7   release_year  8807 non-null   int64\n",
      " 8   rating        8803 non-null   str  \n",
      " 9   duration      8804 non-null   str  \n",
      " 10  listed_in     8807 non-null   str  \n",
      " 11  description   8807 non-null   str  \n",
      "dtypes: int64(1), str(11)\n",
      "memory usage: 825.8 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88af8457",
   "metadata": {},
   "source": [
    "## 3. Data Quality Assessment (Before Cleaning)\n",
    "Assess the data quality to identify missing values, duplicates, and data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eaa10162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "DATA QUALITY ASSESSMENT\n",
      "======================================================================\n",
      "\n",
      "1. Dataset Overview:\n",
      "   Total Records: 8807\n",
      "   Total Columns: 12\n",
      "\n",
      "2. Missing Values:\n",
      "            Missing Count  Percentage\n",
      "director             2634       29.91\n",
      "cast                  825        9.37\n",
      "country               831        9.44\n",
      "date_added             10        0.11\n",
      "rating                  4        0.05\n",
      "duration                3        0.03\n",
      "\n",
      "3. Duplicate Records:\n",
      "   Total Duplicates: 0\n",
      "\n",
      "4. Data Types:\n",
      "show_id           str\n",
      "type              str\n",
      "title             str\n",
      "director          str\n",
      "cast              str\n",
      "country           str\n",
      "date_added        str\n",
      "release_year    int64\n",
      "rating            str\n",
      "duration          str\n",
      "listed_in         str\n",
      "description       str\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "def assess_data_quality(df):\n",
    "    \"\"\"Assess data quality before cleaning.\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"DATA QUALITY ASSESSMENT\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    print(\"\\n1. Dataset Overview:\")\n",
    "    print(f\"   Total Records: {len(df)}\")\n",
    "    print(f\"   Total Columns: {len(df.columns)}\")\n",
    "    \n",
    "    print(\"\\n2. Missing Values:\")\n",
    "    missing = df.isnull().sum()\n",
    "    missing_pct = (missing / len(df) * 100).round(2)\n",
    "    missing_df = pd.DataFrame({\n",
    "        'Missing Count': missing,\n",
    "        'Percentage': missing_pct\n",
    "    })\n",
    "    print(missing_df[missing_df['Missing Count'] > 0])\n",
    "    \n",
    "    print(\"\\n3. Duplicate Records:\")\n",
    "    duplicates = df.duplicated().sum()\n",
    "    print(f\"   Total Duplicates: {duplicates}\")\n",
    "    \n",
    "    print(\"\\n4. Data Types:\")\n",
    "    print(df.dtypes)\n",
    "    \n",
    "    return {\n",
    "        'total_records': len(df),\n",
    "        'missing_values': missing.sum(),\n",
    "        'duplicates': duplicates\n",
    "    }\n",
    "\n",
    "# Assess data quality\n",
    "original_quality = assess_data_quality(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c982b33",
   "metadata": {},
   "source": [
    "## 4. Clean the Dataset\n",
    "Handle missing values and remove duplicate records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccf90cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "CLEANING DATASET\n",
      "======================================================================\n",
      "\n",
      "1. Removing Duplicates...\n",
      "   ✓ Removed 0 duplicate records\n",
      "\n",
      "2. Handling Missing Values...\n",
      "   ✓ director: Filled 2634 missing values (29.91%) with 'Unknown'\n",
      "   ✓ cast: Filled 825 missing values (9.37%) with 'Unknown'\n",
      "   ✓ country: Filled 831 missing values (9.44%) with 'Unknown'\n",
      "   ✓ date_added: Filled 10 missing values (0.11%) with 'Unknown'\n",
      "   ✓ rating: Filled 4 missing values (0.05%) with 'Not Rated'\n",
      "   ✓ duration: Filled 3 missing values (0.03%) with 'Unknown'\n",
      "\n",
      "   ✓ All missing values handled successfully!\n",
      "   ✓ Final Record Count: 8807\n"
     ]
    }
   ],
   "source": [
    "def clean_dataset(df):\n",
    "    \"\"\"Clean the dataset: handle missing values and remove duplicates.\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"CLEANING DATASET\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # Remove duplicate records\n",
    "    print(\"\\n1. Removing Duplicates...\")\n",
    "    initial_count = len(df_clean)\n",
    "    df_clean = df_clean.drop_duplicates()\n",
    "    duplicates_removed = initial_count - len(df_clean)\n",
    "    print(f\"   ✓ Removed {duplicates_removed} duplicate records\")\n",
    "    \n",
    "    # Handle missing values based on data quality assessment\n",
    "    print(\"\\n2. Handling Missing Values...\")\n",
    "    \n",
    "    # High missing values (>29%): director\n",
    "    if 'director' in df_clean.columns:\n",
    "        missing_before = df_clean['director'].isnull().sum()\n",
    "        if missing_before > 0:\n",
    "            df_clean['director'] = df_clean['director'].fillna('Unknown')\n",
    "            print(f\"   ✓ director: Filled {missing_before} missing values ({(missing_before/len(df_clean)*100):.2f}%) with 'Unknown'\")\n",
    "    \n",
    "    # Moderate missing values (5-10%): cast, country\n",
    "    if 'cast' in df_clean.columns:\n",
    "        missing_before = df_clean['cast'].isnull().sum()\n",
    "        if missing_before > 0:\n",
    "            df_clean['cast'] = df_clean['cast'].fillna('Unknown')\n",
    "            print(f\"   ✓ cast: Filled {missing_before} missing values ({(missing_before/len(df_clean)*100):.2f}%) with 'Unknown'\")\n",
    "    \n",
    "    if 'country' in df_clean.columns:\n",
    "        missing_before = df_clean['country'].isnull().sum()\n",
    "        if missing_before > 0:\n",
    "            df_clean['country'] = df_clean['country'].fillna('Unknown')\n",
    "            print(f\"   ✓ country: Filled {missing_before} missing values ({(missing_before/len(df_clean)*100):.2f}%) with 'Unknown'\")\n",
    "    \n",
    "    # Low missing values (<1%): date_added, rating, duration\n",
    "    if 'date_added' in df_clean.columns:\n",
    "        missing_before = df_clean['date_added'].isnull().sum()\n",
    "        if missing_before > 0:\n",
    "            df_clean['date_added'] = df_clean['date_added'].fillna('Unknown')\n",
    "            print(f\"   ✓ date_added: Filled {missing_before} missing values ({(missing_before/len(df_clean)*100):.2f}%) with 'Unknown'\")\n",
    "    \n",
    "    if 'rating' in df_clean.columns:\n",
    "        missing_before = df_clean['rating'].isnull().sum()\n",
    "        if missing_before > 0:\n",
    "            df_clean['rating'] = df_clean['rating'].fillna('Not Rated')\n",
    "            print(f\"   ✓ rating: Filled {missing_before} missing values ({(missing_before/len(df_clean)*100):.2f}%) with 'Not Rated'\")\n",
    "    \n",
    "    if 'duration' in df_clean.columns:\n",
    "        missing_before = df_clean['duration'].isnull().sum()\n",
    "        if missing_before > 0:\n",
    "            df_clean['duration'] = df_clean['duration'].fillna('Unknown')\n",
    "            print(f\"   ✓ duration: Filled {missing_before} missing values ({(missing_before/len(df_clean)*100):.2f}%) with 'Unknown'\")\n",
    "    \n",
    "    # Handle other potential missing values\n",
    "    if 'listed_in' in df_clean.columns:\n",
    "        missing_before = df_clean['listed_in'].isnull().sum()\n",
    "        if missing_before > 0:\n",
    "            df_clean['listed_in'] = df_clean['listed_in'].fillna('Uncategorized')\n",
    "            print(f\"   ✓ listed_in: Filled {missing_before} missing values with 'Uncategorized'\")\n",
    "    \n",
    "    if 'description' in df_clean.columns:\n",
    "        missing_before = df_clean['description'].isnull().sum()\n",
    "        if missing_before > 0:\n",
    "            df_clean['description'] = df_clean['description'].fillna('No description available')\n",
    "            print(f\"   ✓ description: Filled {missing_before} missing values with 'No description available'\")\n",
    "    \n",
    "    # Check for any remaining missing values\n",
    "    remaining_missing = df_clean.isnull().sum().sum()\n",
    "    if remaining_missing == 0:\n",
    "        print(f\"\\n   ✓ All missing values handled successfully!\")\n",
    "    else:\n",
    "        print(f\"\\n   ⚠ Warning: {remaining_missing} missing values remain in other columns\")\n",
    "    \n",
    "    print(f\"   ✓ Final Record Count: {len(df_clean)}\")\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "# Clean the dataset\n",
    "df_cleaned = clean_dataset(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b92f0a",
   "metadata": {},
   "source": [
    "## 5. Normalize Categorical Features\n",
    "Standardize genre, rating, and country columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "026c1367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "NORMALIZING CATEGORICAL FEATURES\n",
      "======================================================================\n",
      "\n",
      "1. Normalizing Genre (listed_in)...\n",
      "   ✓ Genres normalized and standardized\n",
      "   ✓ Unique genre combinations: 514\n",
      "   ✓ Unique individual genres: 42\n",
      "\n",
      "2. Normalizing Rating...\n",
      "   ✓ Ratings normalized to uppercase\n",
      "   ✓ Unique ratings: 18\n",
      "   ✓ Rating categories: ['66 MIN', '74 MIN', '84 MIN', 'G', 'NC-17', 'NOT RATED', 'NR', 'PG', 'PG-13', 'R', 'TV-14', 'TV-G', 'TV-MA', 'TV-PG', 'TV-Y', 'TV-Y7', 'TV-Y7-FV', 'UR']\n",
      "\n",
      "3. Normalizing Country...\n",
      "   ✓ Countries normalized and standardized\n",
      "   ✓ Unique primary countries: 87\n",
      "   ✓ Total unique countries (including co-productions): 124\n",
      "\n",
      "4. Normalizing Content Type...\n",
      "   ✓ Content types: {'Movie': np.int64(6131), 'TV Show': np.int64(2676)}\n"
     ]
    }
   ],
   "source": [
    "def normalize_categorical_features(df):\n",
    "    \"\"\"Normalize genre, rating, and country columns.\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"NORMALIZING CATEGORICAL FEATURES\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    df_normalized = df.copy()\n",
    "    \n",
    "    # Normalize Genre (listed_in)\n",
    "    if 'listed_in' in df_normalized.columns:\n",
    "        print(\"\\n1. Normalizing Genre (listed_in)...\")\n",
    "        df_normalized['listed_in'] = df_normalized['listed_in'].str.strip()\n",
    "        df_normalized['genre_list'] = df_normalized['listed_in'].apply(\n",
    "            lambda x: [g.strip() for g in str(x).split(',')] if pd.notnull(x) else []\n",
    "        )\n",
    "        unique_genres = df_normalized['listed_in'].nunique()\n",
    "        print(f\"   ✓ Genres normalized and standardized\")\n",
    "        print(f\"   ✓ Unique genre combinations: {unique_genres}\")\n",
    "        \n",
    "        all_genres = []\n",
    "        for genres in df_normalized['genre_list']:\n",
    "            all_genres.extend(genres)\n",
    "        unique_individual = len(set(all_genres))\n",
    "        print(f\"   ✓ Unique individual genres: {unique_individual}\")\n",
    "    \n",
    "    # Normalize Rating\n",
    "    if 'rating' in df_normalized.columns:\n",
    "        print(\"\\n2. Normalizing Rating...\")\n",
    "        df_normalized['rating'] = df_normalized['rating'].str.strip().str.upper()\n",
    "        unique_ratings = df_normalized['rating'].nunique()\n",
    "        print(f\"   ✓ Ratings normalized to uppercase\")\n",
    "        print(f\"   ✓ Unique ratings: {unique_ratings}\")\n",
    "        print(f\"   ✓ Rating categories: {sorted(df_normalized['rating'].unique())}\")\n",
    "    \n",
    "    # Normalize Country\n",
    "    if 'country' in df_normalized.columns:\n",
    "        print(\"\\n3. Normalizing Country...\")\n",
    "        df_normalized['country'] = df_normalized['country'].str.strip()\n",
    "        df_normalized['country_list'] = df_normalized['country'].apply(\n",
    "            lambda x: [c.strip() for c in str(x).split(',')] if pd.notnull(x) else []\n",
    "        )\n",
    "        df_normalized['primary_country'] = df_normalized['country_list'].apply(\n",
    "            lambda x: x[0] if len(x) > 0 else 'Unknown'\n",
    "        )\n",
    "        unique_countries = df_normalized['primary_country'].nunique()\n",
    "        print(f\"   ✓ Countries normalized and standardized\")\n",
    "        print(f\"   ✓ Unique primary countries: {unique_countries}\")\n",
    "        \n",
    "        all_countries = []\n",
    "        for countries in df_normalized['country_list']:\n",
    "            all_countries.extend(countries)\n",
    "        unique_individual = len(set(all_countries))\n",
    "        print(f\"   ✓ Total unique countries (including co-productions): {unique_individual}\")\n",
    "    \n",
    "    # Normalize Content Type\n",
    "    if 'type' in df_normalized.columns:\n",
    "        print(\"\\n4. Normalizing Content Type...\")\n",
    "        df_normalized['type'] = df_normalized['type'].str.strip()\n",
    "        content_types = df_normalized['type'].value_counts()\n",
    "        print(f\"   ✓ Content types: {dict(content_types)}\")\n",
    "    \n",
    "    return df_normalized\n",
    "\n",
    "# Normalize categorical features\n",
    "df_normalized = normalize_categorical_features(df_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc768017",
   "metadata": {},
   "source": [
    "## 6. Generate Data Quality Report\n",
    "Generate a comprehensive report showing the improvements after cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc14c227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "DATA QUALITY REPORT (AFTER CLEANING)\n",
      "======================================================================\n",
      "\n",
      "1. Cleaning Summary:\n",
      "   Original Records: 8807\n",
      "   Final Records: 8807\n",
      "   Records Removed: 0\n",
      "\n",
      "2. Missing Values After Cleaning:\n",
      "   ✓ No missing values remaining!\n",
      "\n",
      "3. Data Completeness:\n",
      "   show_id: 100.0%\n",
      "   type: 100.0%\n",
      "   title: 100.0%\n",
      "   director: 100.0%\n",
      "   cast: 100.0%\n",
      "   country: 100.0%\n",
      "   date_added: 100.0%\n",
      "   release_year: 100.0%\n",
      "   rating: 100.0%\n",
      "   duration: 100.0%\n",
      "   listed_in: 100.0%\n",
      "   description: 100.0%\n",
      "   genre_list: 100.0%\n",
      "   country_list: 100.0%\n",
      "   primary_country: 100.0%\n",
      "\n",
      "4. Key Statistics:\n",
      "   Content Types: {'Movie': 6131, 'TV Show': 2676}\n",
      "   Top 5 Ratings: {'TV-MA': 3207, 'TV-14': 2160, 'TV-PG': 863, 'R': 799, 'PG-13': 490}\n",
      "   Top 5 Countries: {'United States': 3211, 'India': 1008, 'Unknown': 831, 'United Kingdom': 628, 'Canada': 271}\n"
     ]
    }
   ],
   "source": [
    "def generate_quality_report(df_original, df_cleaned):\n",
    "    \"\"\"Generate final data quality report.\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"DATA QUALITY REPORT (AFTER CLEANING)\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    print(\"\\n1. Cleaning Summary:\")\n",
    "    print(f\"   Original Records: {len(df_original)}\")\n",
    "    print(f\"   Final Records: {len(df_cleaned)}\")\n",
    "    print(f\"   Records Removed: {len(df_original) - len(df_cleaned)}\")\n",
    "    \n",
    "    print(\"\\n2. Missing Values After Cleaning:\")\n",
    "    missing = df_cleaned.isnull().sum()\n",
    "    if missing.sum() == 0:\n",
    "        print(\"   ✓ No missing values remaining!\")\n",
    "    else:\n",
    "        print(missing[missing > 0])\n",
    "    \n",
    "    print(\"\\n3. Data Completeness:\")\n",
    "    completeness = ((len(df_cleaned) - df_cleaned.isnull().sum()) / len(df_cleaned) * 100).round(2)\n",
    "    for col in df_cleaned.columns:\n",
    "        print(f\"   {col}: {completeness[col]}%\")\n",
    "    \n",
    "    print(\"\\n4. Key Statistics:\")\n",
    "    if 'type' in df_cleaned.columns:\n",
    "        print(f\"   Content Types: {df_cleaned['type'].value_counts().to_dict()}\")\n",
    "    if 'rating' in df_cleaned.columns:\n",
    "        print(f\"   Top 5 Ratings: {df_cleaned['rating'].value_counts().head().to_dict()}\")\n",
    "    if 'primary_country' in df_cleaned.columns:\n",
    "        print(f\"   Top 5 Countries: {df_cleaned['primary_country'].value_counts().head().to_dict()}\")\n",
    "    \n",
    "    return {\n",
    "        'original_records': len(df_original),\n",
    "        'final_records': len(df_cleaned),\n",
    "        'completeness': completeness.mean()\n",
    "    }\n",
    "\n",
    "# Generate quality report\n",
    "final_quality = generate_quality_report(df, df_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3aa7af9",
   "metadata": {},
   "source": [
    "## 7. Save Cleaned Dataset\n",
    "Save the cleaned and normalized dataset to a new CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b659a9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "SAVING CLEANED DATASET\n",
      "======================================================================\n",
      "✓ Cleaned dataset saved as 'netflix_titles_cleaned.csv'\n",
      "  - Shape: 8807 rows × 15 columns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def save_cleaned_dataset(df, output_filename='netflix_titles_cleaned.csv'):\n",
    "    \"\"\"Save the cleaned and normalized dataset.\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"SAVING CLEANED DATASET\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    try:\n",
    "        df.to_csv(output_filename, index=False)\n",
    "        print(f\"✓ Cleaned dataset saved as '{output_filename}'\")\n",
    "        print(f\"  - Shape: {df.shape[0]} rows × {df.shape[1]} columns\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error saving dataset: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "# Save the cleaned dataset\n",
    "save_cleaned_dataset(df_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9c7f23",
   "metadata": {},
   "source": [
    "## 8. Summary and Next Steps\n",
    "\n",
    "### ✅ Milestone 1 Completed!\n",
    "\n",
    "**What we accomplished:**\n",
    "- ✓ Loaded 8,807 Netflix titles (6,131 movies + 2,676 TV shows)\n",
    "- ✓ Cleaned dataset: Handled 4,307 missing values across 6 columns\n",
    "- ✓ Achieved 100% data completeness\n",
    "- ✓ Normalized categorical features:\n",
    "  - **Genre:** 42 unique individual genres\n",
    "  - **Rating:** 18 rating categories\n",
    "  - **Country:** 124 countries\n",
    "- ✓ Created enhanced dataset with 3 additional columns (genre_list, country_list, primary_country)\n",
    "\n",
    "**Output Files:**\n",
    "- `netflix_titles_cleaned.csv` - Clean dataset ready for analysis\n",
    "\n",
    "**Next Steps:**\n",
    "- Exploratory Data Analysis (EDA)\n",
    "- Visualization of trends and patterns\n",
    "- Statistical analysis\n",
    "- Potential modeling (recommendation systems, predictions, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d854f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preview of Cleaned Dataset:\n",
      "\n",
      "First 5 rows:\n",
      "  show_id     type                  title         director  \\\n",
      "0      s1    Movie   Dick Johnson Is Dead  Kirsten Johnson   \n",
      "1      s2  TV Show          Blood & Water          Unknown   \n",
      "2      s3  TV Show              Ganglands  Julien Leclercq   \n",
      "3      s4  TV Show  Jailbirds New Orleans          Unknown   \n",
      "4      s5  TV Show           Kota Factory          Unknown   \n",
      "\n",
      "                                                cast        country  \\\n",
      "0                                            Unknown  United States   \n",
      "1  Ama Qamata, Khosi Ngema, Gail Mabalane, Thaban...   South Africa   \n",
      "2  Sami Bouajila, Tracy Gotoas, Samuel Jouy, Nabi...        Unknown   \n",
      "3                                            Unknown        Unknown   \n",
      "4  Mayur More, Jitendra Kumar, Ranjan Raj, Alam K...          India   \n",
      "\n",
      "           date_added  release_year rating   duration  \\\n",
      "0  September 25, 2021          2020  PG-13     90 min   \n",
      "1  September 24, 2021          2021  TV-MA  2 Seasons   \n",
      "2  September 24, 2021          2021  TV-MA   1 Season   \n",
      "3  September 24, 2021          2021  TV-MA   1 Season   \n",
      "4  September 24, 2021          2021  TV-MA  2 Seasons   \n",
      "\n",
      "                                           listed_in  \\\n",
      "0                                      Documentaries   \n",
      "1    International TV Shows, TV Dramas, TV Mysteries   \n",
      "2  Crime TV Shows, International TV Shows, TV Act...   \n",
      "3                             Docuseries, Reality TV   \n",
      "4  International TV Shows, Romantic TV Shows, TV ...   \n",
      "\n",
      "                                         description  \\\n",
      "0  As her father nears the end of his life, filmm...   \n",
      "1  After crossing paths at a party, a Cape Town t...   \n",
      "2  To protect his family from a powerful drug lor...   \n",
      "3  Feuds, flirtations and toilet talk go down amo...   \n",
      "4  In a city of coaching centers known to train I...   \n",
      "\n",
      "                                          genre_list     country_list  \\\n",
      "0                                    [Documentaries]  [United States]   \n",
      "1  [International TV Shows, TV Dramas, TV Mysteries]   [South Africa]   \n",
      "2  [Crime TV Shows, International TV Shows, TV Ac...        [Unknown]   \n",
      "3                           [Docuseries, Reality TV]        [Unknown]   \n",
      "4  [International TV Shows, Romantic TV Shows, TV...          [India]   \n",
      "\n",
      "  primary_country  \n",
      "0   United States  \n",
      "1    South Africa  \n",
      "2         Unknown  \n",
      "3         Unknown  \n",
      "4           India  \n",
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 8807 entries, 0 to 8806\n",
      "Data columns (total 15 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   show_id          8807 non-null   str   \n",
      " 1   type             8807 non-null   str   \n",
      " 2   title            8807 non-null   str   \n",
      " 3   director         8807 non-null   str   \n",
      " 4   cast             8807 non-null   str   \n",
      " 5   country          8807 non-null   str   \n",
      " 6   date_added       8807 non-null   str   \n",
      " 7   release_year     8807 non-null   int64 \n",
      " 8   rating           8807 non-null   str   \n",
      " 9   duration         8807 non-null   str   \n",
      " 10  listed_in        8807 non-null   str   \n",
      " 11  description      8807 non-null   str   \n",
      " 12  genre_list       8807 non-null   object\n",
      " 13  country_list     8807 non-null   object\n",
      " 14  primary_country  8807 non-null   str   \n",
      "dtypes: int64(1), object(2), str(12)\n",
      "memory usage: 1.0+ MB\n",
      "None\n",
      "\n",
      "Basic Statistics:\n",
      "       show_id   type                 title director     cast        country  \\\n",
      "count     8807   8807                  8807     8807     8807           8807   \n",
      "unique    8807      2                  8807     4529     7693            749   \n",
      "top         s1  Movie  Dick Johnson Is Dead  Unknown  Unknown  United States   \n",
      "freq         1   6131                     1     2634      825           2818   \n",
      "mean       NaN    NaN                   NaN      NaN      NaN            NaN   \n",
      "std        NaN    NaN                   NaN      NaN      NaN            NaN   \n",
      "min        NaN    NaN                   NaN      NaN      NaN            NaN   \n",
      "25%        NaN    NaN                   NaN      NaN      NaN            NaN   \n",
      "50%        NaN    NaN                   NaN      NaN      NaN            NaN   \n",
      "75%        NaN    NaN                   NaN      NaN      NaN            NaN   \n",
      "max        NaN    NaN                   NaN      NaN      NaN            NaN   \n",
      "\n",
      "             date_added  release_year rating  duration  \\\n",
      "count              8807   8807.000000   8807      8807   \n",
      "unique             1768           NaN     18       221   \n",
      "top     January 1, 2020           NaN  TV-MA  1 Season   \n",
      "freq                109           NaN   3207      1793   \n",
      "mean                NaN   2014.180198    NaN       NaN   \n",
      "std                 NaN      8.819312    NaN       NaN   \n",
      "min                 NaN   1925.000000    NaN       NaN   \n",
      "25%                 NaN   2013.000000    NaN       NaN   \n",
      "50%                 NaN   2017.000000    NaN       NaN   \n",
      "75%                 NaN   2019.000000    NaN       NaN   \n",
      "max                 NaN   2021.000000    NaN       NaN   \n",
      "\n",
      "                           listed_in  \\\n",
      "count                           8807   \n",
      "unique                           514   \n",
      "top     Dramas, International Movies   \n",
      "freq                             362   \n",
      "mean                             NaN   \n",
      "std                              NaN   \n",
      "min                              NaN   \n",
      "25%                              NaN   \n",
      "50%                              NaN   \n",
      "75%                              NaN   \n",
      "max                              NaN   \n",
      "\n",
      "                                              description  \\\n",
      "count                                                8807   \n",
      "unique                                               8775   \n",
      "top     Paranormal activity at a lush, abandoned prope...   \n",
      "freq                                                    4   \n",
      "mean                                                  NaN   \n",
      "std                                                   NaN   \n",
      "min                                                   NaN   \n",
      "25%                                                   NaN   \n",
      "50%                                                   NaN   \n",
      "75%                                                   NaN   \n",
      "max                                                   NaN   \n",
      "\n",
      "                            genre_list     country_list primary_country  \n",
      "count                             8807             8807            8807  \n",
      "unique                             514              749              87  \n",
      "top     [Dramas, International Movies]  [United States]   United States  \n",
      "freq                               362             2818            3211  \n",
      "mean                               NaN              NaN             NaN  \n",
      "std                                NaN              NaN             NaN  \n",
      "min                                NaN              NaN             NaN  \n",
      "25%                                NaN              NaN             NaN  \n",
      "50%                                NaN              NaN             NaN  \n",
      "75%                                NaN              NaN             NaN  \n",
      "max                                NaN              NaN             NaN  \n"
     ]
    }
   ],
   "source": [
    "# Preview the cleaned dataset\n",
    "print(\"Preview of Cleaned Dataset:\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df_normalized.head())\n",
    "print(\"\\nDataset Info:\")\n",
    "print(df_normalized.info())\n",
    "print(\"\\nBasic Statistics:\")\n",
    "print(df_normalized.describe(include='all'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
